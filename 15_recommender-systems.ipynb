{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Lecture 15: DBSCAN and Recommender Systems\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"Function_code/.\")\n",
    "import matplotlib.pyplot as plt\n",
    "#from plotting_functions import *\n",
    "#from plotting_functions_unsup import *\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 16\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "plt.style.use(\"seaborn\")\n",
    "%matplotlib inline\n",
    "pd.set_option(\"display.max_colwidth\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lecture plan for today\n",
    "\n",
    "- DBSCAN (~20 mins)\n",
    "- Recommender systems motivation (~5 mins)\n",
    "- Utility matrix (~10 mins)\n",
    "- Break (~5 mins)\n",
    "- Recommender systems dataset and baselines (~15 mins)\n",
    "- Collaborative filtering with `surprise` package (~15 mins)\n",
    "- Summary and final comments (~5 mins) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Learning outcomes <a name=\"lo\"></a>\n",
    "\n",
    "From this lecture, students are expected to be able to:\n",
    "- Identify limitations of K-Means.\n",
    "- Explain how DBSCAN works at a high level.\n",
    "- Use `sklearn` to apply DBSCAN. \n",
    "- Explain the effect of epsilon and minimum samples hyperparameters in DBSCAN.  \n",
    "- Identify DBSCAN limitations.\n",
    "- State the problem of recommender systems. \n",
    "- Describe components of a utility matrix. \n",
    "- Create a utility matrix given ratings data. \n",
    "- Describe a common approach to evaluate recommender systems. \n",
    "- Implement some baseline approaches to complete the utility matrix. \n",
    "- Explain the idea of collaborative filtering. \n",
    "- Explain some serious consequences of recommendation systems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Another useful clustering algorithm: DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### K-Means recap \n",
    "- We discussed K-Means clustering in the previous lecture. \n",
    "- Each cluster is represented by a center. \n",
    "- Given a new point, you can assign it to a cluster by computing the distances to all cluster centers and picking the cluster with the smallest distance. \n",
    "- It's a popular algorithm because \n",
    "    - It's easy to understand and implement.\n",
    "    - Runs relatively quickly and scales well to large datasets. \n",
    "    - `sklearn` has a more scalable variant called [`MiniBatchKMeans`](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.MiniBatchKMeans.html) which can handle very large datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### K-Means limitations\n",
    "\n",
    "- Relies on random initialization and so the outcome may change depending upon this initialization. \n",
    "- K-Means clustering requires to specify the number of clusters in advance.\n",
    "- Very often you do not know the centers in advance. The elbow method or the silhouette method to find the optimal number of clusters are not always easy to interpret. \n",
    "- Each point has to have a cluster assignment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### K-Means limitations: Shape of K-Means clusters\n",
    "\n",
    "- K-Means partitions the space based on the closest mean. \n",
    "- Each cluster is defined solely by its center and so it can only capture relatively simple shapes. \n",
    "- So the boundaries between clusters are linear; It fails to identify clusters with complex shapes. \n",
    "\n",
    "![](img/kmeans_boundaries.png)\n",
    "\n",
    "<!-- <img src=\"img/kmeans_boundaries.png\" alt=\"\" height=\"500\" width=\"500\">  -->\n",
    "    \n",
    "\n",
    "[Source](https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_digits.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### K-Means: failure case 1\n",
    "\n",
    "- K-Means performs poorly if the clusters have more complex shapes (e.g., two moons data below). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=200, noise=0.05, random_state=42)\n",
    "plot_X_k_means(X, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### K-Means: failure case 2\n",
    "\n",
    "- It assumes that all directions are equally important for each cluster and fails to identify non-spherical clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some random cluster data\n",
    "X, y = make_blobs(random_state=170, n_samples=200)\n",
    "rng = np.random.RandomState(74)\n",
    "transformation = rng.normal(size=(2, 2))\n",
    "X = np.dot(X, transformation)\n",
    "plot_X_k_means(X, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### K-Means: failure case 3 \n",
    "\n",
    "- Again, K-Means is unable to capture complex cluster shapes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = datasets.make_circles(n_samples=200, noise=0.06, factor=0.4)[0]\n",
    "plot_X_k_means(X, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Can we do better than this? \n",
    "- Another clustering algorithm called DBSCAN is able to tackle some of these cases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### DBSCAN\n",
    "\n",
    "- **D**ensity-**B**ased **S**patial **C**lustering of **A**pplications with **N**oise\n",
    "- Intuitively, it's based on the idea that clusters form dense regions in the data and so it works by identifying \"crowded\" regions in the feature space. \n",
    "- It can address some of the limitations of K-Means we saw above. \n",
    "    - It does not require the user to specify the number of clusters in advance. \n",
    "    - It can identify points that are not part of any clusters. \n",
    "    - It can capture clusters of complex shapes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's try `sklearn`'s DBSCAN.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "X, y = make_moons(n_samples=200, noise=0.08, random_state=42)\n",
    "dbscan = DBSCAN(eps=0.2)\n",
    "dbscan.fit(X)\n",
    "plot_X_dbscan(X, dbscan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "dbscan.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- DBSCAN is able to capture half moons shape\n",
    "- We don't not have to specify the number of clusters. \n",
    "    - That said, it has two other non-trivial hyperparameters to tune. \n",
    "- There are two examples which have not been assigned any label (noise examples). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "One more example of DBSCAN clusters capturing complex cluster shapes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = datasets.make_circles(n_samples=200, noise=0.06, factor=0.4)[0]\n",
    "dbscan = DBSCAN(eps=0.3, min_samples=3)\n",
    "dbscan.fit(X)\n",
    "plot_X_dbscan(X, dbscan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How does it work?\n",
    "\n",
    "- Iterative algorithm. (We won't go into the details.)  \n",
    "- Based on the idea that clusters form dense regions in the data. \n",
    "\n",
    "![](img/DBSCAN_search.gif)\n",
    "\n",
    "<!-- <img src=\"img/DBSCAN_search.gif\" alt=\"\" height=\"900\" width=\"900\">  -->\n",
    "\n",
    "[Source](https://dashee87.github.io/data%20science/general/Clustering-with-Scikit-with-GIFs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Two main hyperparameters\n",
    "- `eps`: determines what it means for points to be \"close\"\n",
    "- `min_samples`: determines the number of **neighboring points** we require to consider in order for a point to be part of a cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Effect of `eps` hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from ipywidgets import interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "X, y = make_blobs(random_state=40, centers=2, n_samples=6)\n",
    "interactive(lambda eps=1: plot_dbscan_with_labels(X, eps), eps=(1, 12, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(euclidean_distances(X, X)).round()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Effect of `min_samples` hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive(\n",
    "    lambda min_samples=1: plot_dbscan_with_labels(X, eps=1.0, min_samples=min_samples),\n",
    "    min_samples=(1, 5, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### K-Means vs. DBSCAN\n",
    "\n",
    "- In DBSCAN, you do not have to specify the number of clusters! \n",
    "    - Instead, you have to tune `eps` and `min_samples`. \n",
    "- Unlike K-Means, DBSCAN doesn't have to assign all points to clusters. \n",
    "    - The label is -1 if a point is unassigned.\n",
    "- Unlike K-Means, there is no `predict` method. \n",
    "    - DBSCAN only really clusters the points you have, not \"new\" or \"test\" points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### More details on DBSCAN\n",
    "\n",
    "- You'll find more details in the lecture notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "There are three kinds of points.\n",
    "\n",
    "- **Core points** are the points that have at least `min_samples` points in the neighborhood.\n",
    "\n",
    "- **Border points** are the points with fewer than `min_samples` points in the neighborhood, but are connected to a core point. \n",
    "\n",
    "- **Noise points** are the points which do not belong to any cluster. In other words, the points which have less that `min_samples` point within distance `eps` of the starting point are noise points. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- Default values for hyperparameters don't work well on toy datasets. \n",
    "- All points have been marked as noise with the default values for `eps` and `min_samples`\n",
    "- Let's examine the effect of changing these hyperparameters. \n",
    "    - noise points: shown in white\n",
    "    - core points: bigger\n",
    "    - border points: smaller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Illustration of hyperparameters `eps` and `min_samples`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "mglearn.plots.plot_dbscan()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Evaluating DBSCAN clusters \n",
    "- We cannot use the elbow method to examine the goodness of clusters created with DBSCAN. \n",
    "- But we can use the silhouette method because it's not dependent on the idea of cluster centers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "X, y = make_blobs(random_state=100, centers=3, n_samples=300)\n",
    "dbscan = DBSCAN(eps=2, min_samples=5)\n",
    "dbscan.fit(X)\n",
    "plot_X_dbscan(X, dbscan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Yellowbrick is designed to work with K-Means and not with DBSCAN.\n",
    "# So it needs the number of clusters stored in n_clusters\n",
    "# It also needs `predict` method to be implemented.\n",
    "# So I'm implementing it here so that we can use Yellowbrick to show Silhouette plots.\n",
    "n_clusters = len(set(dbscan.labels_))\n",
    "dbscan.n_clusters = n_clusters\n",
    "dbscan.predict = lambda x: dbscan.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan.n_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "\n",
    "visualizer = SilhouetteVisualizer(dbscan, colors=\"yellowbrick\")\n",
    "visualizer.fit(X)  # Fit the data to the visualizer\n",
    "visualizer.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Observations\n",
    "\n",
    "- Increasing `eps` ($\\uparrow$) (left to right in the plot above) means more points will be included in a cluster. \n",
    "    - `eps` = 1.0 either creates more clusters or more noise points, whereas eps=3.0 puts all points in one cluster with no noise points.  \n",
    "- Increasing `min_samples` ($\\uparrow$) (top to bottom in the plot above) means points in less dense regions will either be labeled as their own cluster or noise. \n",
    "    - `min_samples=2`, for instance, has none or only a fewer noise points whereas `min_samples=5` has several noise points. \n",
    "- Here `min_samples` = 2.0 or 3.0 and `eps` = 1.5 is giving us the best results. \n",
    "- In general, it's not trivial to tune these hyperparameters. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary: Pros and cons\n",
    "\n",
    "- Pros\n",
    "    - Can learn arbitrary cluster shapes\n",
    "    - Can detect outliers \n",
    "- Cons\n",
    "    - Cannot `predict` on new examples.  \n",
    "    - Needs tuning of two non-obvious hyperparameters \n",
    "\n",
    "There is an improved version of DBSCAN called [`HDBSCAN` (hierarchical DBSCAN)](https://github.com/scikit-learn-contrib/hdbscan). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### DBSCAN: failure cases\n",
    "\n",
    "- DBSCAN is able to capture complex clusters. But this doesn't mean that `DBSCAN` always works better. It has its own problems! \n",
    "- DBSCAN doesn't do well when we have clusters with different densities. \n",
    "    - You can play with the hyperparameters but it's not likely to help much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_varied, y_varied = make_blobs(\n",
    "    n_samples=200, cluster_std=[1.0, 5.0, 1.0], random_state=10\n",
    ")\n",
    "plot_k_means_dbscan_comparison(X_varied)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```{note}\n",
    "There is also \"hierarchical\" clustering. We don't have time to talk about it. But if you want to know more about it, check out the notes from last year [here](https://github.com/UBC-CS/cpsc330/blob/v2.0/lectures/19_clustering.ipynb).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recommender systems motivation <a name=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is a recommender system? \n",
    "\n",
    "- A recommender or a recommendation system **recommends** a particular product or service to users they are likely to consume. \n",
    "\n",
    "![](img/recommendation_system.png)\n",
    "\n",
    "<!-- <img src=\"img/recommendation_system.png\" alt=\"\" height=\"900\" width=\"900\">  -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Recommender Systems\n",
    "- A client goes to Amazon to buy products. \n",
    "- Amazon has some information about the client. They also have information about other clients buying similar products. \n",
    "- What should they recommend to the client, so that they buy more products? \n",
    "- There's no \"right\" answer (no label). \n",
    "- The whole idea is to understand user behavior in order to recommend them products they are likely to consume. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why should we care about recommendation systems? \n",
    "\n",
    "- Almost everything we buy or consume today is in some way or the other influenced by recommendation systems. \n",
    "    - Music (Spotify), videos (YouTube), news, books and products (Amazon), movies (Netflix), jokes, restaurants, dating , friends (Facebook), professional connections (Linkedin)\n",
    "- Recommendation systems are at the core of the success of many companies. \n",
    "    - Amazon\n",
    "    - [Netflix](https://help.netflix.com/en/node/100639)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### An example Capstone project: [QxMD](https://qxmd.com/)\n",
    "\n",
    "- Present personalized journal article recommendations to health care professionals.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What kind of data we need to build recommendation systems? \n",
    "\n",
    "- **User ratings data** (most common)\n",
    "- **Features related to items or users** \n",
    "- Customer purchase history data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Main approaches\n",
    "\n",
    "- Collaborative filtering \n",
    "    - \"Unsupervised\" learning \n",
    "    - We only have labels $y_{ij}$ (rating of user $i$ for item $j$). \n",
    "    - We learn features.  \n",
    "- Content-based recommenders \n",
    "    - Supervised learning\n",
    "    - Extract features $x_i$ of users and/or items and building a model to predict rating $y_i$ given $x_i$. \n",
    "    - Apply model to predict for new users/items. \n",
    "- Hybrid \n",
    "    - Combining collaborative filtering with content-based filtering\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Netflix prize\n",
    "\n",
    "![](img/netflix.png)\n",
    "\n",
    "[Source](https://netflixtechblog.com/netflix-recommendations-beyond-the-5-stars-part-1-55838468f429)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Netflix prize\n",
    "\n",
    "- 100M ratings from 0.5M users on 18k movies.\n",
    "- Grand prize was \\$1M for first team to reduce squared error at least by 10%.\n",
    "- Winning entry (and most entries) used collaborative filtering:\n",
    "    - Methods that only looks at ratings, not features of movies/users.\n",
    "- A simple collaborative filtering method that does really well:\n",
    "   - Now adopted by many companies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Break (5 min)\n",
    "\n",
    "![](img/eva-coffee.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recommender systems problem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Problem formulation\n",
    "\n",
    "- Most often the data for recommender systems come in as **ratings** for a set of items from a set of users. \n",
    "- We have two entities: $N$ **users** and $M$ **items**. \n",
    "- **Users** are consumers. \n",
    "- **Items** are the products or services offered.  \n",
    "    - E.g., movies (Netflix), books (Amazon), songs (spotify), people (tinder)  \n",
    "    \n",
    "![](img/utility_matrix.png)\n",
    "\n",
    "<!-- <img src=\"img/utility_matrix.png\" alt=\"\" height=\"900\" width=\"900\">  -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Utility matrix \n",
    "\n",
    "- A **utility matrix** is the matrix that captures **interactions** between $N$ **users** and $M$ **items**. \n",
    "- The interaction may come in different forms: \n",
    "    - ratings, clicks, purchases\n",
    "\n",
    "![](img/utility_matrix.png)\n",
    "\n",
    "<!-- <img src=\"img/utility_mat.png\" alt=\"\" height=\"900\" width=\"900\">  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Utility matrix\n",
    "\n",
    "- Below is a toy utility matrix. Here $N$ = 6 and $M$ = 5.  \n",
    "- Each entry $y_{ij}$ ($i^{th}$ row and $j^{th}$ column) denotes the rating given by the user $i$ to item $j$. \n",
    "- We represent users in terms of items and items in terms of users. \n",
    "\n",
    "![](img/utility_matrix.png)\n",
    "\n",
    "<!-- <img src=\"img/utility_matrix.png\" alt=\"\" height=\"900\" width=\"900\">  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sparsity of utility matrix\n",
    "\n",
    "- The utility matrix is very sparse because usually users only interact with a few items. \n",
    "- For example: \n",
    "    - all Netflix users will have rated only a small percentage of content available on Netflix\n",
    "    - all amazon clients will have rated only a small fraction of items among all items available on Amazon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What do we predict? \n",
    "Given a utility matrix of $N$ users and $M$ items, **complete the utility matrix**. In other words, **predict missing values in the matrix**. \n",
    "\n",
    "![](img/utility_matrix.png)\n",
    "\n",
    "<!-- <img src=\"img/utility_matrix.png\" alt=\"\" height=\"900\" width=\"900\">  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Once we have predicted ratings, we can recommend items to users they are likely to rate higher. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example dataset: [Jester 1.7M jokes ratings dataset](https://www.kaggle.com/vikashrajluhaniwal/jester-17m-jokes-ratings-dataset?select=jester_ratings.csv)\n",
    "\n",
    "- We'll use a sample of [Jester 1.7M jokes ratings dataset](https://www.kaggle.com/vikashrajluhaniwal/jester-17m-jokes-ratings-dataset) to demonstrate different recommendation systems. \n",
    "\n",
    "The dataset comes with two CSVs\n",
    "- A CSV containing ratings (-10.0 to +10.0) of 150 jokes from 59,132 users. \n",
    "- A CSV containing joke IDs and the actual text of jokes. \n",
    "\n",
    "> Some jokes might be offensive. Please do not look too much into the actual text data if you are sensitive to such language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Recommendation systems are most effective when you have a large amount of data.\n",
    "- But we are only taking a sample here for speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "filename = \"data/jester_ratings.csv\"\n",
    "ratings_full = pd.read_csv(filename)\n",
    "ratings = ratings_full[ratings_full[\"userId\"] <= 4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>jokeId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>-9.281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>-9.281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>-6.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  jokeId  rating\n",
       "0  1       5       0.219 \n",
       "1  1       7      -9.281 \n",
       "2  1       8      -9.281 \n",
       "3  1       13     -6.781 \n",
       "4  1       15      0.875 "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141362, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_key = \"userId\"\n",
    "item_key = \"jokeId\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Dataset stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 141362 entries, 0 to 141361\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   userId  141362 non-null  int64  \n",
      " 1   jokeId  141362 non-null  int64  \n",
      " 2   rating  141362 non-null  float64\n",
      "dtypes: float64(1), int64(2)\n",
      "memory usage: 4.3 MB\n"
     ]
    }
   ],
   "source": [
    "ratings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ratings: 141362\n",
      "Average rating:  1.200\n",
      "Number of users (N): 3635\n",
      "Number of items (M): 140\n",
      "Fraction non-nan ratings: 0.278\n"
     ]
    }
   ],
   "source": [
    "def get_stats(ratings, item_key=\"jokeId\", user_key=\"userId\"):\n",
    "    print(\"Number of ratings:\", len(ratings))\n",
    "    print(\"Average rating:  %0.3f\" % (np.mean(ratings[\"rating\"])))\n",
    "    N = len(np.unique(ratings[user_key]))\n",
    "    M = len(np.unique(ratings[item_key]))\n",
    "    print(\"Number of users (N): %d\" % N)\n",
    "    print(\"Number of items (M): %d\" % M)\n",
    "    print(\"Fraction non-nan ratings: %0.3f\" % (len(ratings) / (N * M)))\n",
    "    return N, M\n",
    "\n",
    "\n",
    "N, M = get_stats(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27777952446453136"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " (len(ratings)/(N*M))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Creating utility matrix\n",
    "\n",
    "- Let's construct utility matrix with `number of users` rows and `number of items` columns from the ratings data. \n",
    "\n",
    "> Note we are constructing a non-sparse matrix for demonstration purpose here. In real life it's recommended that you work with sparse matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3635, 140)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_mapper = dict(zip(np.unique(ratings[user_key]), list(range(N))))\n",
    "item_mapper = dict(zip(np.unique(ratings[item_key]), list(range(M))))\n",
    "user_inverse_mapper = dict(zip(list(range(N)), np.unique(ratings[user_key])))\n",
    "item_inverse_mapper = dict(zip(list(range(M)), np.unique(ratings[item_key])))\n",
    "\n",
    "\n",
    "def create_Y_from_ratings(data, N, M):\n",
    "    Y = np.zeros((N, M))\n",
    "    Y.fill(np.nan)\n",
    "    for index, val in data.iterrows():\n",
    "        n = user_mapper[val[user_key]]\n",
    "        m = item_mapper[val[item_key]]\n",
    "        Y[n, m] = val[\"rating\"]\n",
    "\n",
    "    return Y\n",
    "\n",
    "\n",
    "Y_mat = create_Y_from_ratings(ratings, N, M)\n",
    "Y_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Utility matrix for the example problem\n",
    "- Rows represent users.\n",
    "- Columns represent items (jokes in our case).\n",
    "- Each cell gives the rating given by the user to the corresponding joke. \n",
    "- Users are features for jokes and jokes are features for users.\n",
    "- We want to predict the missing entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.219</td>\n",
       "      <td>-9.281</td>\n",
       "      <td>-9.281</td>\n",
       "      <td>-6.781</td>\n",
       "      <td>0.875</td>\n",
       "      <td>-9.656</td>\n",
       "      <td>-9.031</td>\n",
       "      <td>-7.469</td>\n",
       "      <td>-8.719</td>\n",
       "      <td>-9.156</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.688</td>\n",
       "      <td>9.938</td>\n",
       "      <td>9.531</td>\n",
       "      <td>9.938</td>\n",
       "      <td>0.406</td>\n",
       "      <td>3.719</td>\n",
       "      <td>9.656</td>\n",
       "      <td>-2.688</td>\n",
       "      <td>-9.562</td>\n",
       "      <td>-9.125</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9.844</td>\n",
       "      <td>-9.844</td>\n",
       "      <td>-7.219</td>\n",
       "      <td>-2.031</td>\n",
       "      <td>-9.938</td>\n",
       "      <td>-9.969</td>\n",
       "      <td>-9.875</td>\n",
       "      <td>-9.812</td>\n",
       "      <td>-9.781</td>\n",
       "      <td>-6.844</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.812</td>\n",
       "      <td>-4.500</td>\n",
       "      <td>-4.906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.906</td>\n",
       "      <td>4.750</td>\n",
       "      <td>-5.906</td>\n",
       "      <td>-0.406</td>\n",
       "      <td>-4.031</td>\n",
       "      <td>3.875</td>\n",
       "      <td>6.219</td>\n",
       "      <td>5.656</td>\n",
       "      <td>6.094</td>\n",
       "      <td>5.406</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3630</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.812</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3631</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.844</td>\n",
       "      <td>7.531</td>\n",
       "      <td>-9.719</td>\n",
       "      <td>-9.344</td>\n",
       "      <td>3.875</td>\n",
       "      <td>9.812</td>\n",
       "      <td>8.938</td>\n",
       "      <td>8.375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3632</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.906</td>\n",
       "      <td>3.969</td>\n",
       "      <td>-2.312</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>-8.844</td>\n",
       "      <td>4.188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3633</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.875</td>\n",
       "      <td>-9.156</td>\n",
       "      <td>-9.156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3634</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.312</td>\n",
       "      <td>1.281</td>\n",
       "      <td>-3.531</td>\n",
       "      <td>2.125</td>\n",
       "      <td>-5.812</td>\n",
       "      <td>5.562</td>\n",
       "      <td>-6.062</td>\n",
       "      <td>0.125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3635 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2      3      4      5      6      7      8      9  \\\n",
       "0     0.219 -9.281 -9.281 -6.781  0.875 -9.656 -9.031 -7.469 -8.719 -9.156   \n",
       "1    -9.688  9.938  9.531  9.938  0.406  3.719  9.656 -2.688 -9.562 -9.125   \n",
       "2    -9.844 -9.844 -7.219 -2.031 -9.938 -9.969 -9.875 -9.812 -9.781 -6.844   \n",
       "3    -5.812 -4.500 -4.906 NaN    NaN    NaN    NaN    NaN    NaN    NaN      \n",
       "4     6.906  4.750 -5.906 -0.406 -4.031  3.875  6.219  5.656  6.094  5.406   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3630 NaN    -9.812 -0.062 NaN    NaN    NaN    NaN    NaN    NaN    NaN      \n",
       "3631 NaN    -9.844  7.531 -9.719 -9.344  3.875  9.812  8.938  8.375 NaN      \n",
       "3632 NaN    -1.906  3.969 -2.312 -0.344 -8.844  4.188 NaN    NaN    NaN      \n",
       "3633 NaN    -8.875 -9.156 -9.156 NaN    NaN    NaN    NaN    NaN    NaN      \n",
       "3634 NaN    -6.312  1.281 -3.531  2.125 -5.812  5.562 -6.062  0.125 NaN      \n",
       "\n",
       "      ...  130  131    132  133  134  135  136  137  138  139  \n",
       "0     ... NaN  NaN  NaN    NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "1     ... NaN  NaN  NaN    NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2     ... NaN  NaN  NaN    NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3     ... NaN  NaN  NaN    NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4     ... NaN  NaN  NaN    NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "...   ...  ..   ..   ..     ..   ..   ..   ..   ..   ..   ..   \n",
       "3630  ... NaN  NaN  NaN    NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3631  ... NaN  NaN  NaN    NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3632  ... NaN  NaN  NaN    NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3633  ... NaN  NaN  NaN    NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3634  ... NaN  NaN   4.188 NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "[3635 rows x 140 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Y_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Baseline Approaches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Recall that our goal is to predict missing entries in the utility matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.219</td>\n",
       "      <td>-9.281</td>\n",
       "      <td>-9.281</td>\n",
       "      <td>-6.781</td>\n",
       "      <td>0.875</td>\n",
       "      <td>-9.656</td>\n",
       "      <td>-9.031</td>\n",
       "      <td>-7.469</td>\n",
       "      <td>-8.719</td>\n",
       "      <td>-9.156</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-9.688</td>\n",
       "      <td>9.938</td>\n",
       "      <td>9.531</td>\n",
       "      <td>9.938</td>\n",
       "      <td>0.406</td>\n",
       "      <td>3.719</td>\n",
       "      <td>9.656</td>\n",
       "      <td>-2.688</td>\n",
       "      <td>-9.562</td>\n",
       "      <td>-9.125</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9.844</td>\n",
       "      <td>-9.844</td>\n",
       "      <td>-7.219</td>\n",
       "      <td>-2.031</td>\n",
       "      <td>-9.938</td>\n",
       "      <td>-9.969</td>\n",
       "      <td>-9.875</td>\n",
       "      <td>-9.812</td>\n",
       "      <td>-9.781</td>\n",
       "      <td>-6.844</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.812</td>\n",
       "      <td>-4.500</td>\n",
       "      <td>-4.906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.906</td>\n",
       "      <td>4.750</td>\n",
       "      <td>-5.906</td>\n",
       "      <td>-0.406</td>\n",
       "      <td>-4.031</td>\n",
       "      <td>3.875</td>\n",
       "      <td>6.219</td>\n",
       "      <td>5.656</td>\n",
       "      <td>6.094</td>\n",
       "      <td>5.406</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3630</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.812</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3631</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.844</td>\n",
       "      <td>7.531</td>\n",
       "      <td>-9.719</td>\n",
       "      <td>-9.344</td>\n",
       "      <td>3.875</td>\n",
       "      <td>9.812</td>\n",
       "      <td>8.938</td>\n",
       "      <td>8.375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3632</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.906</td>\n",
       "      <td>3.969</td>\n",
       "      <td>-2.312</td>\n",
       "      <td>-0.344</td>\n",
       "      <td>-8.844</td>\n",
       "      <td>4.188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3633</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-8.875</td>\n",
       "      <td>-9.156</td>\n",
       "      <td>-9.156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3634</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.312</td>\n",
       "      <td>1.281</td>\n",
       "      <td>-3.531</td>\n",
       "      <td>2.125</td>\n",
       "      <td>-5.812</td>\n",
       "      <td>5.562</td>\n",
       "      <td>-6.062</td>\n",
       "      <td>0.125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3635 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0      1      2      3      4      5      6      7      8      9  \\\n",
       "0     0.219 -9.281 -9.281 -6.781  0.875 -9.656 -9.031 -7.469 -8.719 -9.156   \n",
       "1    -9.688  9.938  9.531  9.938  0.406  3.719  9.656 -2.688 -9.562 -9.125   \n",
       "2    -9.844 -9.844 -7.219 -2.031 -9.938 -9.969 -9.875 -9.812 -9.781 -6.844   \n",
       "3    -5.812 -4.500 -4.906 NaN    NaN    NaN    NaN    NaN    NaN    NaN      \n",
       "4     6.906  4.750 -5.906 -0.406 -4.031  3.875  6.219  5.656  6.094  5.406   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "3630 NaN    -9.812 -0.062 NaN    NaN    NaN    NaN    NaN    NaN    NaN      \n",
       "3631 NaN    -9.844  7.531 -9.719 -9.344  3.875  9.812  8.938  8.375 NaN      \n",
       "3632 NaN    -1.906  3.969 -2.312 -0.344 -8.844  4.188 NaN    NaN    NaN      \n",
       "3633 NaN    -8.875 -9.156 -9.156 NaN    NaN    NaN    NaN    NaN    NaN      \n",
       "3634 NaN    -6.312  1.281 -3.531  2.125 -5.812  5.562 -6.062  0.125 NaN      \n",
       "\n",
       "      ...  130  131    132  133  134  135  136  137  138  139  \n",
       "0     ... NaN  NaN  NaN    NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "1     ... NaN  NaN  NaN    NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "2     ... NaN  NaN  NaN    NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3     ... NaN  NaN  NaN    NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "4     ... NaN  NaN  NaN    NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "...   ...  ..   ..   ..     ..   ..   ..   ..   ..   ..   ..   \n",
       "3630  ... NaN  NaN  NaN    NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3631  ... NaN  NaN  NaN    NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3632  ... NaN  NaN  NaN    NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3633  ... NaN  NaN  NaN    NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "3634  ... NaN  NaN   4.188 NaN  NaN  NaN  NaN  NaN  NaN  NaN   \n",
       "\n",
       "[3635 rows x 140 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Y_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Evaluation\n",
    "\n",
    "- We'll try a number of methods to do this. \n",
    "- Although there is no notion of \"accurate\" recommendations, we need a way to evaluate our predictions so that we'll be able to compare different methods.\n",
    "- Although we are doing unsupervised learning, we'll split the data and evaluate our predictions as follows.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Data splitting \n",
    "\n",
    "- We split the ratings into train and validation sets. \n",
    "- It's easier to split the ratings data instead of splitting the utility matrix.\n",
    "- Don't worry about `y`; we're not really going to use it.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((113089, 3), (28273, 3))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = ratings.copy()\n",
    "y = ratings[user_key]\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train.shape, X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now we will create utility matrices for train and validation splits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "train_mat = create_Y_from_ratings(X_train, N, M)\n",
    "valid_mat = create_Y_from_ratings(X_valid, N, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3635, 140), (3635, 140))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mat.shape, valid_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `train_mat` has only ratings from the train set and `valid_mat` has only ratings from the valid set.\n",
    "- During training we assume that we do not have access to some of the available ratings. We predict these ratings and evaluate them against ratings in the validation set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Questions for you\n",
    "\n",
    "- How do train and validation utility matrices differ? \n",
    "- Why are utility matrices for train and validation sets are of the same shape?\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "**Answer:**\n",
    "\n",
    "- The training matrix `train_mat` is of shape N by M but only has ratings from `X_train` and all other ratings missing. \n",
    "- The validation matrix `valid_mat` is also of shape N by M but it only has ratings `X_valid` and all other ratings missing. \n",
    "- They have the same shape because both have the same number of users and items; that's how we have constructed them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Evaluation\n",
    "\n",
    "- Now that we have train and validation sets, how do we evaluate our predictions?\n",
    "- You can calculate the error between actual ratings and predicted ratings with metrics of your choice. \n",
    "    - Most common ones are MSE or RMSE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- The `error` function below calculates RMSE and `evaluate` function prints train and validation RMSE.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(X1, X2):\n",
    "    \"\"\"\n",
    "    Returns the root mean squared error.\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.nanmean((X1 - X2) ** 2))  \n",
    "\n",
    "\n",
    "def evaluate(pred_X, train_X, valid_X, model_name=\"Global average\"):\n",
    "    print(\"%s train RMSE: %0.2f\" % (model_name, error(pred_X, train_X)))\n",
    "    print(\"%s valid RMSE: %0.2f\" % (model_name, error(pred_X, valid_X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Baselines\n",
    "\n",
    "Let's first try some simple approaches to predict missing entries. \n",
    "\n",
    "1. Global average baseline\n",
    "2. [$k$-Nearest Neighbours imputation](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html)    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Global average baseline\n",
    "\n",
    "- Let's examine RMSE of the global average baseline. \n",
    "- In this baseline we predict everything as the global average rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>...</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>...</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>...</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>...</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>...</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "      <td>1.20741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1        2        3        4        5        6        7  \\\n",
       "0  1.20741  1.20741  1.20741  1.20741  1.20741  1.20741  1.20741  1.20741   \n",
       "1  1.20741  1.20741  1.20741  1.20741  1.20741  1.20741  1.20741  1.20741   \n",
       "2  1.20741  1.20741  1.20741  1.20741  1.20741  1.20741  1.20741  1.20741   \n",
       "3  1.20741  1.20741  1.20741  1.20741  1.20741  1.20741  1.20741  1.20741   \n",
       "4  1.20741  1.20741  1.20741  1.20741  1.20741  1.20741  1.20741  1.20741   \n",
       "\n",
       "         8        9  ...      130      131      132      133      134  \\\n",
       "0  1.20741  1.20741  ...  1.20741  1.20741  1.20741  1.20741  1.20741   \n",
       "1  1.20741  1.20741  ...  1.20741  1.20741  1.20741  1.20741  1.20741   \n",
       "2  1.20741  1.20741  ...  1.20741  1.20741  1.20741  1.20741  1.20741   \n",
       "3  1.20741  1.20741  ...  1.20741  1.20741  1.20741  1.20741  1.20741   \n",
       "4  1.20741  1.20741  ...  1.20741  1.20741  1.20741  1.20741  1.20741   \n",
       "\n",
       "       135      136      137      138      139  \n",
       "0  1.20741  1.20741  1.20741  1.20741  1.20741  \n",
       "1  1.20741  1.20741  1.20741  1.20741  1.20741  \n",
       "2  1.20741  1.20741  1.20741  1.20741  1.20741  \n",
       "3  1.20741  1.20741  1.20741  1.20741  1.20741  \n",
       "4  1.20741  1.20741  1.20741  1.20741  1.20741  \n",
       "\n",
       "[5 rows x 140 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg = np.nanmean(train_mat)\n",
    "pred_g = np.zeros(train_mat.shape) + avg\n",
    "pd.DataFrame(pred_g).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global average train RMSE: 5.75\n",
      "Global average valid RMSE: 5.77\n"
     ]
    }
   ],
   "source": [
    "evaluate(pred_g, train_mat, valid_mat, model_name=\"Global average\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [$k$-nearest neighbours imputation](https://scikit-learn.org/stable/modules/generated/sklearn.impute.KNNImputer.html)\n",
    "\n",
    "- Can we try $k$-nearest neighbours type imputation? \n",
    "- Impute missing values using the mean value from $k$ nearest neighbours found in the training set. \n",
    "- Calculate distances between examples using features where neither value is missing. \n",
    "\n",
    "![](img/utility_matrix.png)\n",
    "\n",
    "<!-- <img src=\"img/utility_matrix.png\" alt=\"\" height=\"900\" width=\"900\">  -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=10)\n",
    "train_mat_imp = imputer.fit_transform(train_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.9406</td>\n",
       "      <td>-9.2810</td>\n",
       "      <td>-9.2810</td>\n",
       "      <td>-6.7810</td>\n",
       "      <td>0.8750</td>\n",
       "      <td>-9.6560</td>\n",
       "      <td>-9.0310</td>\n",
       "      <td>-7.4690</td>\n",
       "      <td>-8.7190</td>\n",
       "      <td>-9.1560</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.5311</td>\n",
       "      <td>1.8968</td>\n",
       "      <td>0.6905</td>\n",
       "      <td>-3.1218</td>\n",
       "      <td>1.2843</td>\n",
       "      <td>-2.6063</td>\n",
       "      <td>-0.1812</td>\n",
       "      <td>-1.3937</td>\n",
       "      <td>1.7625</td>\n",
       "      <td>-0.4092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.3405</td>\n",
       "      <td>9.9380</td>\n",
       "      <td>9.5310</td>\n",
       "      <td>9.9380</td>\n",
       "      <td>0.4060</td>\n",
       "      <td>3.7190</td>\n",
       "      <td>9.6560</td>\n",
       "      <td>-2.6880</td>\n",
       "      <td>4.3438</td>\n",
       "      <td>-9.1250</td>\n",
       "      <td>...</td>\n",
       "      <td>2.2437</td>\n",
       "      <td>3.1719</td>\n",
       "      <td>5.0251</td>\n",
       "      <td>5.1812</td>\n",
       "      <td>8.2407</td>\n",
       "      <td>5.9311</td>\n",
       "      <td>5.8375</td>\n",
       "      <td>6.3812</td>\n",
       "      <td>1.1687</td>\n",
       "      <td>6.2532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9.8440</td>\n",
       "      <td>-3.5750</td>\n",
       "      <td>-7.2190</td>\n",
       "      <td>-2.0310</td>\n",
       "      <td>-9.9380</td>\n",
       "      <td>-9.9690</td>\n",
       "      <td>-9.8750</td>\n",
       "      <td>-9.8120</td>\n",
       "      <td>-9.7810</td>\n",
       "      <td>-6.8440</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.4186</td>\n",
       "      <td>-3.1156</td>\n",
       "      <td>-1.5655</td>\n",
       "      <td>-5.6250</td>\n",
       "      <td>0.3720</td>\n",
       "      <td>-4.0439</td>\n",
       "      <td>-6.0500</td>\n",
       "      <td>-5.5563</td>\n",
       "      <td>-5.4125</td>\n",
       "      <td>-5.5874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.8120</td>\n",
       "      <td>-2.4624</td>\n",
       "      <td>-4.9060</td>\n",
       "      <td>-2.7781</td>\n",
       "      <td>-0.0532</td>\n",
       "      <td>-3.8594</td>\n",
       "      <td>1.7031</td>\n",
       "      <td>-0.3687</td>\n",
       "      <td>1.8469</td>\n",
       "      <td>0.0593</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.0344</td>\n",
       "      <td>2.1469</td>\n",
       "      <td>2.8875</td>\n",
       "      <td>1.6845</td>\n",
       "      <td>1.2437</td>\n",
       "      <td>-0.0156</td>\n",
       "      <td>1.2595</td>\n",
       "      <td>3.8219</td>\n",
       "      <td>3.1971</td>\n",
       "      <td>5.0249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.3157</td>\n",
       "      <td>4.7500</td>\n",
       "      <td>1.8658</td>\n",
       "      <td>-0.4060</td>\n",
       "      <td>1.7937</td>\n",
       "      <td>3.8750</td>\n",
       "      <td>6.2190</td>\n",
       "      <td>1.9220</td>\n",
       "      <td>6.0940</td>\n",
       "      <td>5.4060</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2844</td>\n",
       "      <td>1.1313</td>\n",
       "      <td>4.0157</td>\n",
       "      <td>3.0344</td>\n",
       "      <td>4.0406</td>\n",
       "      <td>0.5218</td>\n",
       "      <td>4.3594</td>\n",
       "      <td>4.0968</td>\n",
       "      <td>3.9250</td>\n",
       "      <td>3.9657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3630</th>\n",
       "      <td>-0.7750</td>\n",
       "      <td>-9.8120</td>\n",
       "      <td>-0.0620</td>\n",
       "      <td>-2.8218</td>\n",
       "      <td>-4.1470</td>\n",
       "      <td>-4.8281</td>\n",
       "      <td>2.2718</td>\n",
       "      <td>-2.8782</td>\n",
       "      <td>-1.0125</td>\n",
       "      <td>0.0688</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.6844</td>\n",
       "      <td>3.0531</td>\n",
       "      <td>2.8687</td>\n",
       "      <td>1.5281</td>\n",
       "      <td>4.5002</td>\n",
       "      <td>-0.1878</td>\n",
       "      <td>2.0031</td>\n",
       "      <td>4.0908</td>\n",
       "      <td>2.3563</td>\n",
       "      <td>5.0406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3631</th>\n",
       "      <td>2.5188</td>\n",
       "      <td>-5.0625</td>\n",
       "      <td>-0.4001</td>\n",
       "      <td>-9.7190</td>\n",
       "      <td>-9.3440</td>\n",
       "      <td>-1.6408</td>\n",
       "      <td>-4.1187</td>\n",
       "      <td>8.9380</td>\n",
       "      <td>8.3750</td>\n",
       "      <td>-0.9314</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.0344</td>\n",
       "      <td>7.9155</td>\n",
       "      <td>3.4282</td>\n",
       "      <td>4.2968</td>\n",
       "      <td>6.7968</td>\n",
       "      <td>7.3999</td>\n",
       "      <td>1.8500</td>\n",
       "      <td>5.8219</td>\n",
       "      <td>5.1812</td>\n",
       "      <td>2.8437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3632</th>\n",
       "      <td>0.1749</td>\n",
       "      <td>-1.9060</td>\n",
       "      <td>3.9690</td>\n",
       "      <td>-1.3844</td>\n",
       "      <td>-0.3440</td>\n",
       "      <td>-8.8440</td>\n",
       "      <td>4.1880</td>\n",
       "      <td>-1.5564</td>\n",
       "      <td>5.0593</td>\n",
       "      <td>0.3343</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.0126</td>\n",
       "      <td>2.8344</td>\n",
       "      <td>2.4499</td>\n",
       "      <td>2.9312</td>\n",
       "      <td>2.3750</td>\n",
       "      <td>-0.4062</td>\n",
       "      <td>1.4375</td>\n",
       "      <td>3.9750</td>\n",
       "      <td>-1.2220</td>\n",
       "      <td>2.8375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3633</th>\n",
       "      <td>-4.5937</td>\n",
       "      <td>-6.4907</td>\n",
       "      <td>-6.1594</td>\n",
       "      <td>-9.1560</td>\n",
       "      <td>-7.1437</td>\n",
       "      <td>-6.5406</td>\n",
       "      <td>3.8718</td>\n",
       "      <td>-1.7782</td>\n",
       "      <td>-3.7406</td>\n",
       "      <td>-0.6406</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.6938</td>\n",
       "      <td>4.8061</td>\n",
       "      <td>4.9968</td>\n",
       "      <td>-0.1626</td>\n",
       "      <td>2.4187</td>\n",
       "      <td>-0.7750</td>\n",
       "      <td>4.6781</td>\n",
       "      <td>1.7658</td>\n",
       "      <td>0.4595</td>\n",
       "      <td>0.1843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3634</th>\n",
       "      <td>-0.0812</td>\n",
       "      <td>-6.3120</td>\n",
       "      <td>1.2810</td>\n",
       "      <td>-3.5310</td>\n",
       "      <td>2.1250</td>\n",
       "      <td>-5.8120</td>\n",
       "      <td>5.5620</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>-1.1874</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.8156</td>\n",
       "      <td>4.1812</td>\n",
       "      <td>4.1880</td>\n",
       "      <td>3.7280</td>\n",
       "      <td>3.0750</td>\n",
       "      <td>2.1033</td>\n",
       "      <td>2.8156</td>\n",
       "      <td>5.5312</td>\n",
       "      <td>3.8283</td>\n",
       "      <td>4.1219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3635 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0       1       2       3       4       5       6       7       8  \\\n",
       "0    -5.9406 -9.2810 -9.2810 -6.7810  0.8750 -9.6560 -9.0310 -7.4690 -8.7190   \n",
       "1     2.3405  9.9380  9.5310  9.9380  0.4060  3.7190  9.6560 -2.6880  4.3438   \n",
       "2    -9.8440 -3.5750 -7.2190 -2.0310 -9.9380 -9.9690 -9.8750 -9.8120 -9.7810   \n",
       "3    -5.8120 -2.4624 -4.9060 -2.7781 -0.0532 -3.8594  1.7031 -0.3687  1.8469   \n",
       "4     1.3157  4.7500  1.8658 -0.4060  1.7937  3.8750  6.2190  1.9220  6.0940   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "3630 -0.7750 -9.8120 -0.0620 -2.8218 -4.1470 -4.8281  2.2718 -2.8782 -1.0125   \n",
       "3631  2.5188 -5.0625 -0.4001 -9.7190 -9.3440 -1.6408 -4.1187  8.9380  8.3750   \n",
       "3632  0.1749 -1.9060  3.9690 -1.3844 -0.3440 -8.8440  4.1880 -1.5564  5.0593   \n",
       "3633 -4.5937 -6.4907 -6.1594 -9.1560 -7.1437 -6.5406  3.8718 -1.7782 -3.7406   \n",
       "3634 -0.0812 -6.3120  1.2810 -3.5310  2.1250 -5.8120  5.5620  0.2218  0.1250   \n",
       "\n",
       "           9  ...     130     131     132     133     134     135     136  \\\n",
       "0    -9.1560  ... -4.5311  1.8968  0.6905 -3.1218  1.2843 -2.6063 -0.1812   \n",
       "1    -9.1250  ...  2.2437  3.1719  5.0251  5.1812  8.2407  5.9311  5.8375   \n",
       "2    -6.8440  ... -4.4186 -3.1156 -1.5655 -5.6250  0.3720 -4.0439 -6.0500   \n",
       "3     0.0593  ... -2.0344  2.1469  2.8875  1.6845  1.2437 -0.0156  1.2595   \n",
       "4     5.4060  ... -0.2844  1.1313  4.0157  3.0344  4.0406  0.5218  4.3594   \n",
       "...      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "3630  0.0688  ... -6.6844  3.0531  2.8687  1.5281  4.5002 -0.1878  2.0031   \n",
       "3631 -0.9314  ... -4.0344  7.9155  3.4282  4.2968  6.7968  7.3999  1.8500   \n",
       "3632  0.3343  ... -4.0126  2.8344  2.4499  2.9312  2.3750 -0.4062  1.4375   \n",
       "3633 -0.6406  ... -4.6938  4.8061  4.9968 -0.1626  2.4187 -0.7750  4.6781   \n",
       "3634 -1.1874  ... -3.8156  4.1812  4.1880  3.7280  3.0750  2.1033  2.8156   \n",
       "\n",
       "         137     138     139  \n",
       "0    -1.3937  1.7625 -0.4092  \n",
       "1     6.3812  1.1687  6.2532  \n",
       "2    -5.5563 -5.4125 -5.5874  \n",
       "3     3.8219  3.1971  5.0249  \n",
       "4     4.0968  3.9250  3.9657  \n",
       "...      ...     ...     ...  \n",
       "3630  4.0908  2.3563  5.0406  \n",
       "3631  5.8219  5.1812  2.8437  \n",
       "3632  3.9750 -1.2220  2.8375  \n",
       "3633  1.7658  0.4595  0.1843  \n",
       "3634  5.5312  3.8283  4.1219  \n",
       "\n",
       "[3635 rows x 140 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_mat_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN imputer train RMSE: 0.00\n",
      "KNN imputer valid RMSE: 4.79\n"
     ]
    }
   ],
   "source": [
    "evaluate(train_mat_imp, train_mat, valid_mat, model_name=\"KNN imputer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Finding [nearest neighbors](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html)\n",
    "\n",
    "- We can look at nearest neighbours of a query item. \n",
    "- Here our columns are jokes, and users are features for jokes, and we'll have to find nearest neighbours of columns vectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(train_mat_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### $k$-nearest neighbours on a query joke\n",
    "- Let's transpose the matrix.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "item_user_mat = train_mat_imp.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jokeId</th>\n",
       "      <th>jokeText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A man visits the doctor. The doctor says \"I have bad news for you.You have\\ncancer and Alzheimer's disease\". \\nThe man replies \"Well,thank God I don't have cancer!\"\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>This couple had an excellent relationship going until one day he came home\\nfrom work to find his girlfriend packing. He asked her why she was leaving him\\nand she told him that she had heard awful things about him. \\n\\n\"What could they possibly have said to make you move out?\" \\n\\n\"They told me that you were a pedophile.\" \\n\\nHe replied, \"That's an awfully big word for a ten year old.\" \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Q. What's 200 feet long and has 4 teeth? \\n\\nA. The front row at a Willie Nelson Concert.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Q. What's the difference between a man and a toilet? \\n\\nA. A toilet doesn't follow you around after you use it.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Q.\\tWhat's O. J. Simpson's Internet address? \\nA.\\tSlash, slash, backslash, slash, slash, escape.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Bill &amp; Hillary are on a trip back to Arkansas. They're almost out of gas, so Bill pulls into a service station on the outskirts of\\ntown. The attendant runs out of the station to serve them when Hillary realizes it's an old boyfriend from high school. She and\\nthe attendant chat as he gases up their car and cleans the windows. Then they all say good-bye. \\n\\nAs Bill pulls the car onto the road, he turns to Hillary and says, 'Now aren't you glad you married me and not him ? You could've\\nbeen the wife of a grease monkey !' \\n\\nTo which Hillary replied, 'No, Bill. If I would have married him, you'd be pumping gas and he would be the President !' \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>How many feminists does it take to screw in a light bulb?\\nThat's not funny.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Q. Did you hear about the dyslexic devil worshiper? \\n\\nA. He sold his soul to Santa.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>A country guy goes into a city bar that has a dress code, and the maitre\\nd' \\ndemands he wear a tie. Discouraged, the guy goes to his car to sulk when \\ninspiration strikes: He's got jumper cables in the trunk! So he wraps\\nthem around his neck, sort of like a string tie (a bulky string tie to be\\nsure) and returns to the bar. The maitre d' is reluctant, but says to the\\nguy, \"Okay, you're a pretty resourceful fellow, you can come in... but\\njust don't start anything\"!  \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Two cannibals are eating a clown, one turns to other and says: \\n\"Does this taste funny to you? \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   jokeId  \\\n",
       "0  1        \n",
       "1  2        \n",
       "2  3        \n",
       "3  4        \n",
       "4  5        \n",
       "5  6        \n",
       "6  7        \n",
       "7  8        \n",
       "8  9        \n",
       "9  10       \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         jokeText  \n",
       "0  A man visits the doctor. The doctor says \"I have bad news for you.You have\\ncancer and Alzheimer's disease\". \\nThe man replies \"Well,thank God I don't have cancer!\"\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          \n",
       "1  This couple had an excellent relationship going until one day he came home\\nfrom work to find his girlfriend packing. He asked her why she was leaving him\\nand she told him that she had heard awful things about him. \\n\\n\"What could they possibly have said to make you move out?\" \\n\\n\"They told me that you were a pedophile.\" \\n\\nHe replied, \"That's an awfully big word for a ten year old.\" \\n                                                                                                                                                                                                                                                                        \n",
       "2  Q. What's 200 feet long and has 4 teeth? \\n\\nA. The front row at a Willie Nelson Concert.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "3  Q. What's the difference between a man and a toilet? \\n\\nA. A toilet doesn't follow you around after you use it.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "4  Q.\\tWhat's O. J. Simpson's Internet address? \\nA.\\tSlash, slash, backslash, slash, slash, escape.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "5  Bill & Hillary are on a trip back to Arkansas. They're almost out of gas, so Bill pulls into a service station on the outskirts of\\ntown. The attendant runs out of the station to serve them when Hillary realizes it's an old boyfriend from high school. She and\\nthe attendant chat as he gases up their car and cleans the windows. Then they all say good-bye. \\n\\nAs Bill pulls the car onto the road, he turns to Hillary and says, 'Now aren't you glad you married me and not him ? You could've\\nbeen the wife of a grease monkey !' \\n\\nTo which Hillary replied, 'No, Bill. If I would have married him, you'd be pumping gas and he would be the President !' \\n  \n",
       "6  How many feminists does it take to screw in a light bulb?\\nThat's not funny.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "7  Q. Did you hear about the dyslexic devil worshiper? \\n\\nA. He sold his soul to Santa.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "8  A country guy goes into a city bar that has a dress code, and the maitre\\nd' \\ndemands he wear a tie. Discouraged, the guy goes to his car to sulk when \\ninspiration strikes: He's got jumper cables in the trunk! So he wraps\\nthem around his neck, sort of like a string tie (a bulky string tie to be\\nsure) and returns to the bar. The maitre d' is reluctant, but says to the\\nguy, \"Okay, you're a pretty resourceful fellow, you can come in... but\\njust don't start anything\"!  \\n                                                                                                                                                                                  \n",
       "9  Two cannibals are eating a clown, one turns to other and says: \\n\"Does this taste funny to you? \\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jokes_df = pd.read_csv(\"data/jester_items.csv\")\n",
    "jokes_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'jokes_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m id_joke_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[43mjokes_df\u001b[49m\u001b[38;5;241m.\u001b[39mjokeId, jokes_df\u001b[38;5;241m.\u001b[39mjokeText))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'jokes_df' is not defined"
     ]
    }
   ],
   "source": [
    "id_joke_map = dict(zip(jokes_df.jokeId, jokes_df.jokeText))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query joke:  Q: If a person who speaks three languages is called \"tri-lingual,\" and\n",
      "a person who speaks two languages is called \"bi-lingual,\" what do call\n",
      "a person who only speaks one language?\n",
      "\n",
      "A: American! \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top recommendations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q: What is the difference between George  Washington, Richard Nixon,\\nand Bill Clinton?\\n\\nA: Washington couldn't tell a lie, Nixon couldn't   tell the truth, and\\nClinton doesn't know the difference.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A man in a hot air balloon realized he was lost. He reduced altitude and spotted a woman below. He descended a bit more and shouted, \"Excuse me, can you help me? I promised a friend I would meet him an hour ago, but I don't know where I am.\" The woman below replied, \"You are in a hot air balloon hovering approximately 30 feet above the ground. You are between 40 and 41 degrees north latitude and between 59 and 60 degrees west longitude.\" \"You must be an engineer,\" said the balloonist. \"I am,\" replied the woman. \"How did you know?\" \"Well,\" answered the balloonist, \"everything you told me is technically correct, but I have no idea what to make of your information, and the fact is, I am still lost. Frankly, you've not been much help so far.\" The woman below responded, \"You must be in management.\" \"I am,\" replied the balloonist, \"but how did you know?\" \"Well,\" said the woman, \"you don't know where you are or where you are going. You have risen to where you are due to a large quantity of hot air. You made a promise that you have no idea how to keep, and you expect people beneath you to solve your problems. The fact is, you are in exactly the same position you were in before we met, but now, somehow, it's my fault!\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If pro- is the opposite of con- then congress must be the opposite\\nof progress.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arnold Swartzeneger and Sylvester Stallone are making a movie about\\nthe lives of the great composers.  \\nStallone says \"I want to be Mozart.\" \\nSwartzeneger says: \"In that case...  I'll be Bach.\"\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             top recommendations\n",
       "0  Q: What is the difference between George  Washington, Richard Nixon,\\nand Bill Clinton?\\n\\nA: Washington couldn't tell a lie, Nixon couldn't   tell the truth, and\\nClinton doesn't know the difference.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   \n",
       "1  A man in a hot air balloon realized he was lost. He reduced altitude and spotted a woman below. He descended a bit more and shouted, \"Excuse me, can you help me? I promised a friend I would meet him an hour ago, but I don't know where I am.\" The woman below replied, \"You are in a hot air balloon hovering approximately 30 feet above the ground. You are between 40 and 41 degrees north latitude and between 59 and 60 degrees west longitude.\" \"You must be an engineer,\" said the balloonist. \"I am,\" replied the woman. \"How did you know?\" \"Well,\" answered the balloonist, \"everything you told me is technically correct, but I have no idea what to make of your information, and the fact is, I am still lost. Frankly, you've not been much help so far.\" The woman below responded, \"You must be in management.\" \"I am,\" replied the balloonist, \"but how did you know?\" \"Well,\" said the woman, \"you don't know where you are or where you are going. You have risen to where you are due to a large quantity of hot air. You made a promise that you have no idea how to keep, and you expect people beneath you to solve your problems. The fact is, you are in exactly the same position you were in before we met, but now, somehow, it's my fault!\"\n",
       "2  If pro- is the opposite of con- then congress must be the opposite\\nof progress.\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "3  Arnold Swartzeneger and Sylvester Stallone are making a movie about\\nthe lives of the great composers.  \\nStallone says \"I want to be Mozart.\" \\nSwartzeneger says: \"In that case...  I'll be Bach.\"\\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "def get_topk_recommendations(X, query_ind=0, metric=\"cosine\", k=5):\n",
    "    query_idx = item_inverse_mapper[query_ind]\n",
    "    model = NearestNeighbors(n_neighbors=k, metric=\"cosine\")\n",
    "    model.fit(X)\n",
    "    neigh_ind = model.kneighbors([X[query_ind]], k, return_distance=False).flatten()\n",
    "    neigh_ind = np.delete(neigh_ind, np.where(query_ind == query_ind))\n",
    "    recs = [id_joke_map[item_inverse_mapper[i]] for i in neigh_ind]\n",
    "    print(\"Query joke: \", id_joke_map[query_idx])\n",
    "\n",
    "    return pd.DataFrame(data=recs, columns=[\"top recommendations\"])\n",
    "\n",
    "\n",
    "get_topk_recommendations(item_user_mat, query_ind=8, metric=\"cosine\", k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Question**\n",
    "- Instead of imputation, what would be the consequences if we replace `nan` with zeros so that we can calculate distances between vectors? \n",
    "\n",
    "<br><br>\n",
    "**Answer**\n",
    "\n",
    "It's not a good idea replace ratings with 0, because 0 can be an actual rating value in our case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What to do with predictions? \n",
    "- Once you have predictions, you can sort them based on ratings and recommend items with highest ratings.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Collaborative filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Collaborative filtering \n",
    "- One of the most popular approach for recommendation systems. \n",
    "- Approach used by the winning entry (and most of the entries) in the Netflix competition. \n",
    "- An unsupervised approach\n",
    "    - Only uses the user-item interactions given in the ratings matrix. \n",
    "- **Intuition**\n",
    "    - We may have similar users and similar items which can help us predict missing entries. \n",
    "    - Leverage social information to provide recommendations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Problem \n",
    "\n",
    "- Given a utility matrix with many missing entries, how can we predict missing ratings?  \n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "? & ? & \\checkmark  & ? & \\checkmark\\\\\n",
    "\\checkmark & ? & ?  & ? & ?\\\\\n",
    "? & \\checkmark & \\checkmark  & ? & \\checkmark\\\\\n",
    "? & ? & ?  & ? & ?\\\\\n",
    "? & ? & ? & \\checkmark & ?\\\\\n",
    "? & \\checkmark & \\checkmark  & ? & \\checkmark\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "> Note: rating prediction $\\neq$ Classification or regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Classification or regression\n",
    "\n",
    "- We have $X$ and targets for some rows in $X$. \n",
    "- We want to predict the last column (target column).  \n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "\\checkmark & \\checkmark & \\checkmark  & \\checkmark & \\checkmark\\\\\n",
    "\\checkmark & \\checkmark & \\checkmark  & \\checkmark & \\checkmark\\\\\n",
    "\\checkmark & \\checkmark & \\checkmark  & \\checkmark & \\checkmark\\\\\n",
    "\\checkmark & \\checkmark & \\checkmark  & \\checkmark & ?\\\\\n",
    "\\checkmark & \\checkmark & \\checkmark  & \\checkmark & ?\\\\\n",
    "\\checkmark & \\checkmark & \\checkmark  & \\checkmark & ?\\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Rating prediction \n",
    "\n",
    "- Ratings data has many missing values in the utility matrix. There is no special target column. We want to predict the missing entries in the matrix. \n",
    "- Since our goal is to **predict** ratings, usually the utility matrix is referred to as $Y$ matrix. \n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} \n",
    "? & ? & \\checkmark  & ? & \\checkmark\\\\\n",
    "\\checkmark & ? & ?  & ? & ?\\\\\n",
    "? & \\checkmark & \\checkmark  & ? & \\checkmark\\\\\n",
    "? & ? & ?  & ? & ?\\\\\n",
    "? & ? & ? & \\checkmark & ?\\\\\n",
    "? & \\checkmark & \\checkmark  & ? & \\checkmark\n",
    "\\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- I'll show you how to use a package which implements collaborative filtering. \n",
    "- We don't have sufficient background to understand how it works under the hood.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Rating prediction using the surprise package\n",
    "\n",
    "- We'll be using a package called [Surprise](https://surprise.readthedocs.io/en/stable/index.html). \n",
    "- The collaborative filtering algorithm we use in this package is called `SVD`. \n",
    "\n",
    "```\n",
    "conda install -c conda-forge scikit-surprise\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's try it out on our Jester dataset utility matrix.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import surprise\n",
    "from surprise import SVD, Dataset, Reader, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader()\n",
    "data = Dataset.load_from_df(ratings, reader)  # Load the data\n",
    "\n",
    "# I'm being sloppy here. Probably there is a way to create validset from our already split data.\n",
    "trainset, validset = surprise.model_selection.train_test_split(\n",
    "    data, test_size=0.2, random_state=42\n",
    ")  # Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "algo = SVD(n_factors=k, random_state=42)\n",
    "algo.fit(trainset)\n",
    "svd_preds = algo.test(validset)\n",
    "accuracy.rmse(svd_preds, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No big improvement over the global baseline (RMSE=5.77). \n",
    "- Probably because we are only considering a sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cross-validation for recommender systems\n",
    "\n",
    "- We can also carry out cross-validation and grid search with this package. \n",
    "- Let's look at an example of cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "results = cross_validate(algo, data, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Jester dataset is available as one of the built-in datasets in this package and you can load it as follows and run cross-validation as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.load_builtin(\"jester\")\n",
    "\n",
    "results = cross_validate(algo, data, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What is content-based filtering? \n",
    "\n",
    "- Supervised machine learning approach\n",
    "- In collaborative filtering we assumed that we only have ratings data. \n",
    "- Usually there is some information on items and users available. \n",
    "- Examples\n",
    "    - Netflix can describe movies as action, romance, comedy, documentaries. \n",
    "    - Amazon could describe books according to topics: math, languages, history. \n",
    "    - Tinder could describe people according to age, location, employment.\n",
    "- Can we use this information to predict ratings in the utility matrix?   \n",
    "    - Yes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid filtering\n",
    "\n",
    "- Combining advantages of collaborative filtering and content-based filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Final comments and summary <a name=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Formulating the problem of recommender systems \n",
    "\n",
    "- We are given ratings data. \n",
    "- We use this data to create **utility matrix** which encodes interactions between users and items. \n",
    "- The utility matrix has many missing entries. \n",
    "- We defined recommendation systems problem as **matrix completion problem**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Collaborative filtering \n",
    "\n",
    "- Collaborative filtering is an unsupervised approach to recommendation systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Evaluation \n",
    "\n",
    "- We split the data similar to supervised systems. \n",
    "- We evaluate recommendation systems using traditional regression metrics such as MSE or RMSE. \n",
    "- But real evaluation of recommender system can be very tricky because there is no ground truth. \n",
    "- We have been using RMSE due to the lack of a better measure.  \n",
    "- What we actually want to measure is the interest that our user has in the recommended items. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Precision at N\n",
    "\n",
    "- Another popular evaluation metric from information retrieval is precision at N. \n",
    "- Suppose you recommend top-N items, then we look at the proportion of the items that are relevant. \n",
    "$$\\text{Precision at } N = \\frac{r}{N}$$\n",
    "- For example, $r$ could be the number of elements in your list that the user rated.\n",
    "- In this way, you would know that your system is recommending items that the user had interest in!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Some thoughts on recommendation systems  \n",
    "- Be mindful of the consequences recommendation systems. \n",
    "- Companies such as Amazon,  Netflix, Facebook, Google (YouTube), which extensively use recommendation systems, are profit-driven and so they design these systems to maximize user attention; their focus is not necessarily human well-being. \n",
    "- There are tons of news and research articles on serious consequences of recommendation systems.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Some thoughts on recommendation systems  \n",
    "\n",
    "- Some weird stories which got media attention.   \n",
    "[How Target Figured Out A Teen Girl Was Pregnant Before Her Father Did](https://www.forbes.com/sites/kashmirhill/2012/02/16/how-target-figured-out-a-teen-girl-was-pregnant-before-her-father-did/?sh=3171af136668)\n",
    "- More serious consequences are in political contexts. \n",
    "    - [Facebook Admits It Was Used to Incite Violence in Myanmar](https://www.nytimes.com/2018/11/06/technology/myanmar-facebook.html)\n",
    "    - [YouTube Extremism and the Long Tail](https://www.theatlantic.com/politics/archive/2018/03/youtube-extremism-and-the-long-tail/555350/)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### My advice\n",
    "\n",
    "- Ask hard and uncomfortable questions to yourself (and to your employer if possible) before implementing and deploying such systems.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Resources \n",
    "\n",
    "- [Collaborative filtering for recommendation systems in Python, by N. Hug](https://www.youtube.com/watch?v=z0dx-YckFko)\n",
    "- [An interesting talk: The paradox of choice](https://www.ted.com/talks/barry_schwartz_the_paradox_of_choice)\n",
    "- [How Netflix’s Recommendations System Works](https://help.netflix.com/en/node/100639)\n",
    "- [Hands on Recommendation Systems with Python](https://learning.oreilly.com/library/view/hands-on-recommendation-systems/9781788993753/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions for class discussion <a name=\"questions\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### True/False questions\n",
    "\n",
    "1. To evaluate rating predictions we split the data. The shapes of validation utility matrix and train utility matrix are the same. \n",
    "2. It would be reasonable to impute missing values in the utility matrix by taking the average of the ratings given to an item by similar users.  \n",
    "3. You might be able to predict missing ratings in the utility matrix using supervised machine learning methods. \n",
    "<br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Discuss a strange/scary experience you had with recommendation systems. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
